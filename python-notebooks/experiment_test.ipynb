{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '../')\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from utils.config import cfg\n",
    "from utils.blocks.forecaster import Forecaster\n",
    "from utils.blocks.encoder import Encoder\n",
    "from utils.tools.ordered_easydict import OrderedDict\n",
    "from utils.blocks.module import EF\n",
    "from utils.loss import Weighted_mse_mae\n",
    "from utils.blocks.trajGRU import TrajGRU\n",
    "from utils.train_and_test import train_and_test\n",
    "from utils.net_params import encoder_params, forecaster_params\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = cfg.GLOBAL.BATCH_SIZE\n",
    "max_iterations = 10 #100000\n",
    "test_iteration_interval = 5 #1000\n",
    "test_and_save_checkpoint_iterations = 5 #1000\n",
    "\n",
    "LR = 1e-4\n",
    "\n",
    "criterion = Weighted_mse_mae().to(cfg.GLOBAL.DEVICE)\n",
    "\n",
    "encoder = Encoder(encoder_params[0], encoder_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "\n",
    "forecaster = Forecaster(forecaster_params[0], forecaster_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "\n",
    "encoder_forecaster = EF(encoder, forecaster).to(cfg.GLOBAL.DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(encoder_forecaster.parameters(), lr=LR)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=LR_step_size, gamma=0.1)\n",
    "mult_step_scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[30000, 60000], gamma=0.1)\n",
    "\n",
    "folder_name = os.path.split(os.path.dirname(os.path.abspath('__file__')))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\FACT-PC\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (0,1,2034,2048) could not be broadcast to indexing result of shape (46,1,2034,2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\FACT-PC\\Desktop\\git_workspace\\Data-Science-Project-2-2021-2-Nowcasting\\python-notebooks\\experiment_test.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/experiment_test.ipynb#ch0000002?line=0'>1</a>\u001b[0m train_and_test(encoder_forecaster, optimizer, criterion, mult_step_scheduler, batch_size, max_iterations, test_iteration_interval, test_and_save_checkpoint_iterations, \u001b[39m\"\u001b[39;49m\u001b[39mtraj\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\FACT-PC\\Desktop\\git_workspace\\Data-Science-Project-2-2021-2-Nowcasting\\python-notebooks\\..\\utils\\train_and_test.py:49\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(encoder_forecaster, optimizer, criterion, lr_scheduler, batch_size, max_iterations, test_iteration_interval, test_and_save_checkpoint_iterations, folder_name, probToPixel)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/train_and_test.py?line=45'>46</a>\u001b[0m \u001b[39mfor\u001b[39;00m itera \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, max_iterations\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)):\n\u001b[0;32m     <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/train_and_test.py?line=46'>47</a>\u001b[0m     \u001b[39m# if itera!=1:\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/train_and_test.py?line=47'>48</a>\u001b[0m     lr_scheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/train_and_test.py?line=48'>49</a>\u001b[0m     train_batch, train_mask, sample_datetimes, _ \u001b[39m=\u001b[39m train_iter\u001b[39m.\u001b[39;49msample(batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[0;32m     <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/train_and_test.py?line=49'>50</a>\u001b[0m     train_batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(train_batch\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32))\u001b[39m.\u001b[39mto(cfg\u001b[39m.\u001b[39mGLOBAL\u001b[39m.\u001b[39mDEVICE) \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/train_and_test.py?line=50'>51</a>\u001b[0m     train_data \u001b[39m=\u001b[39m train_batch[:IN_LEN, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\FACT-PC\\Desktop\\git_workspace\\Data-Science-Project-2-2021-2-Nowcasting\\python-notebooks\\..\\utils\\tools\\dataloader.py:358\u001b[0m, in \u001b[0;36mBKKIterator.sample\u001b[1;34m(self, batch_size, only_return_datetime)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=355'>356</a>\u001b[0m                 datetime_clips\u001b[39m.\u001b[39mappend(datetime_clip)\n\u001b[0;32m    <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=356'>357</a>\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=357'>358</a>\u001b[0m frame_dat, mask_dat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_frames(datetime_clips\u001b[39m=\u001b[39;49mdatetime_clips)\n\u001b[0;32m    <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=358'>359</a>\u001b[0m \u001b[39mreturn\u001b[39;00m frame_dat, mask_dat, datetime_clips, new_start\n",
      "File \u001b[1;32mc:\\Users\\FACT-PC\\Desktop\\git_workspace\\Data-Science-Project-2-2021-2-Nowcasting\\python-notebooks\\..\\utils\\tools\\dataloader.py:226\u001b[0m, in \u001b[0;36mBKKIterator._load_frames\u001b[1;34m(self, datetime_clips)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=223'>224</a>\u001b[0m     all_mask_dat \u001b[39m=\u001b[39m quick_read_masks(mask_paths)\n\u001b[0;32m    <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=224'>225</a>\u001b[0m     frame_dat[hit_inds[:, \u001b[39m0\u001b[39m], hit_inds[:, \u001b[39m1\u001b[39m], :, :, :] \u001b[39m=\u001b[39m all_frame_dat\n\u001b[1;32m--> <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=225'>226</a>\u001b[0m     mask_dat[hit_inds[:, \u001b[39m0\u001b[39m], hit_inds[:, \u001b[39m1\u001b[39m], :, :, :] \u001b[39m=\u001b[39m all_mask_dat\n\u001b[0;32m    <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=226'>227</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=227'>228</a>\u001b[0m     \u001b[39m# Get the first_timestamp and the last_timestamp in the datetime_clips\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/FACT-PC/Desktop/git_workspace/Data-Science-Project-2-2021-2-Nowcasting/python-notebooks/../utils/tools/dataloader.py?line=228'>229</a>\u001b[0m     first_timestamp \u001b[39m=\u001b[39m datetime_clips[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: value array of shape (0,1,2034,2048) could not be broadcast to indexing result of shape (46,1,2034,2048)"
     ]
    }
   ],
   "source": [
    "train_and_test(encoder_forecaster, optimizer, criterion, mult_step_scheduler, batch_size, max_iterations, test_iteration_interval, test_and_save_checkpoint_iterations, \"traj\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb1796cbf25d2108f32d5db083036b25e583e4721264bccb55031d3096240637"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
