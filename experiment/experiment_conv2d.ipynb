{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "fSIUm0DokSjb"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/One-Night-Miracle/Data-Science-Project-2-2021-2-Nowcasting.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "evgM30H-JLyz"
      },
      "outputs": [],
      "source": [
        "# !rm -rf /content/Data-Science-Project-2-2021-2-Nowcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "0MMA5z6UqVUt"
      },
      "outputs": [],
      "source": [
        "# !mv '/content/Data-Science-Project-2-2021-2-Nowcasting/data/bkk_radar_images_dBZ' '/content/'\n",
        "# !mv '/content/Data-Science-Project-2-2021-2-Nowcasting/data/bkk_radar_images_mask' '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "mQug86Xjkz-S"
      },
      "outputs": [],
      "source": [
        "# import gdown\n",
        "\n",
        "# urls = ['https://drive.google.com/drive/folders/1cs3sv5raII2sD1Sbz2cad0BDX-MRJ_nS?usp=sharing', 'https://drive.google.com/drive/folders/1vDnxOsk2PLhX3YUW_bysa0t-Ap1YkiAO?usp=sharing']\n",
        "# gdown.download_folder(urls[0], quiet=True)\n",
        "# gdown.download_folder(urls[1], quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "_atSz5tem-dg"
      },
      "outputs": [],
      "source": [
        "# !mv '/content/bkk_radar_images_dBZ' '/content/Data-Science-Project-2-2021-2-Nowcasting/data/'\n",
        "# !mv '/content/bkk_radar_images_mask' '/content/Data-Science-Project-2-2021-2-Nowcasting/data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "61SNyEQXmuJk"
      },
      "outputs": [],
      "source": [
        "# !unzip -q '/content/Data-Science-Project-2-2021-2-Nowcasting/data/bkk_radar_images_dBZ/*' -d '/content/Data-Science-Project-2-2021-2-Nowcasting/data/bkk_radar_images_dBZ/'\n",
        "# !unzip -q '/content/Data-Science-Project-2-2021-2-Nowcasting/data/bkk_radar_images_mask/*' -d '/content/Data-Science-Project-2-2021-2-Nowcasting/data/bkk_radar_images_mask/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "faHrZcJiEo6E"
      },
      "outputs": [],
      "source": [
        "# !rm /content/Data-Science-Project-2-2021-2-Nowcasting/data/bkk_radar_images_dBZ/*.zip\n",
        "# !rm /content/Data-Science-Project-2-2021-2-Nowcasting/data/bkk_radar_images_mask/*.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "7zvJq6-Clr70"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "FZVonPYSkReX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os, sys\n",
        "sys.path.insert(0, '/content/Data-Science-Project-2-2021-2-Nowcasting/')\n",
        "\n",
        "from utils.config import cfg\n",
        "from utils.blocks.forecaster import Forecaster\n",
        "from utils.blocks.encoder import Encoder\n",
        "from utils.tools.ordered_easydict import OrderedDict\n",
        "from utils.blocks.module import EF\n",
        "from utils.loss import Weighted_mse_mae\n",
        "from utils.train_and_test import train_and_test\n",
        "from experiment.net_params import conv2d_params\n",
        "from utils.blocks.module import Predictor\n",
        "\n",
        "if not os.path.exists(cfg.GLOBAL.MODEL_SAVE_DIR):\n",
        "    os.makedirs(cfg.GLOBAL.MODEL_SAVE_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWmWJacio2jl"
      },
      "source": [
        "## Train-Valid-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "mKbkYBq1litw"
      },
      "outputs": [],
      "source": [
        "from utils.tools.train_test_split import *\n",
        "\n",
        "train_test_split(cfg.ONM_PD.FOLDER_ALL, ratio=(0.8,0.05,0.15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcaH-rRGpCbU"
      },
      "source": [
        "## Experiment Conv2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "IQWB0ZEHpEYy"
      },
      "outputs": [],
      "source": [
        "batch_size = cfg.GLOBAL.BATCH_SIZE\n",
        "max_iterations = 20000\n",
        "test_iteration_interval = 2000\n",
        "test_and_save_checkpoint_iterations = 2000\n",
        "\n",
        "LR = 1e-4\n",
        "\n",
        "criterion = Weighted_mse_mae().to(cfg.GLOBAL.DEVICE)\n",
        "\n",
        "model = Predictor(conv2d_params).to(cfg.GLOBAL.DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-6)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=4000, gamma=0.7)\n",
        "folder_name = \"conv2d\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moPX6jTbq-9G"
      },
      "source": [
        "### Verifying model network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpyEPZn3prae",
        "outputId": "b0351df3-6ccc-44ba-f43c-75945bf23f18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Predictor(\n",
              "  (model): Sequential(\n",
              "    (conv1_relu_1): Conv2d(5, 64, kernel_size=(7, 7), stride=(5, 5), padding=(1, 1))\n",
              "    (relu_conv1_relu_1): ReLU(inplace=True)\n",
              "    (conv2_relu_1): Conv2d(64, 192, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
              "    (relu_conv2_relu_1): ReLU(inplace=True)\n",
              "    (conv3_relu_1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (relu_conv3_relu_1): ReLU(inplace=True)\n",
              "    (deconv1_relu_1): ConvTranspose2d(192, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (relu_deconv1_relu_1): ReLU(inplace=True)\n",
              "    (deconv2_relu_1): ConvTranspose2d(192, 64, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
              "    (relu_deconv2_relu_1): ReLU(inplace=True)\n",
              "    (deconv3_relu_1): ConvTranspose2d(64, 64, kernel_size=(7, 7), stride=(5, 5), padding=(1, 1))\n",
              "    (relu_deconv3_relu_1): ReLU(inplace=True)\n",
              "    (conv3_relu_2): Conv2d(64, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu_conv3_relu_2): ReLU(inplace=True)\n",
              "    (conv3_3): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS2fi4Mcq43_"
      },
      "source": [
        "### Verifying input/output shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-hgEIBDpJyV",
        "outputId": "29509c08-08a7-454f-e532-9ce4ccc3aa42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20, 4, 1, 480, 480])\n"
          ]
        }
      ],
      "source": [
        "data = torch.randn(5, 4, 1, 480, 480)\n",
        "output = model(data.cuda())\n",
        "print(output.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq3W5PttMEV-"
      },
      "source": [
        "### Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXcuogZ-rBuH",
        "outputId": "80c3dae3-31ba-485a-b381-ceecc419fd15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            " 21%|██▏       | 4293/20000 [1:11:23<2:17:53,  1.90it/s]"
          ]
        }
      ],
      "source": [
        "train_and_test(model, optimizer, criterion, exp_lr_scheduler, batch_size, max_iterations, test_iteration_interval, test_and_save_checkpoint_iterations, folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9oOZfTTQ7B5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTg6fVTIiX3M"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRKm1blpiZwl"
      },
      "outputs": [],
      "source": [
        "# from utils.tools.evaluation import *\n",
        "# from utils.tools.dataloader import BKKIterator\n",
        "# import copy\n",
        "# import time\n",
        "# import pickle\n",
        "\n",
        "# IN_LEN = cfg.BENCHMARK.IN_LEN\n",
        "# OUT_LEN = cfg.BENCHMARK.OUT_LEN\n",
        "# name = 'conv2d'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNupQPkLibL1"
      },
      "outputs": [],
      "source": [
        "# with torch.no_grad():\n",
        "#     is_deeplearning_model = (torch.nn.Module in model.__class__.__bases__)\n",
        "#     if is_deeplearning_model:\n",
        "#         model.eval()\n",
        "#     evaluator = Evaluation(seq_len=OUT_LEN, use_central=False)\n",
        "#     bkk_iter = BKKIterator(pd_path=cfg.ONM_PD.RAINY_TEST,\n",
        "#                                     sample_mode=\"sequent\",\n",
        "#                                     seq_len=IN_LEN + OUT_LEN,\n",
        "#                                     stride=cfg.BENCHMARK.STRIDE)\n",
        "#     model_run_avarage_time = dict()\n",
        "#     model_run_avarage_time[name] = 0.0\n",
        "#     valid_time = 0\n",
        "#     while not bkk_iter.use_up:\n",
        "#         valid_batch, valid_mask, sample_datetimes, _ = bkk_iter.sample(batch_size=1)\n",
        "#         if valid_batch.shape[1] == 0:\n",
        "#             break\n",
        "#         if not cfg.EVALUATION.VALID_DATA_USE_UP and valid_time > cfg.EVALUATION.VALID_TIME:\n",
        "#             break\n",
        "\n",
        "#         valid_batch = valid_batch.astype(np.float32) / 255.0\n",
        "#         valid_data = valid_batch[:IN_LEN, ...]\n",
        "#         valid_label = valid_batch[IN_LEN:IN_LEN + OUT_LEN, ...]\n",
        "#         mask = valid_mask[IN_LEN:IN_LEN + OUT_LEN, ...].astype(int)\n",
        "\n",
        "#         if is_deeplearning_model:\n",
        "#             valid_data = torch.from_numpy(valid_data).to(cfg.GLOBAL.DEVICE)\n",
        "\n",
        "#         start = time.time()\n",
        "#         output = model(valid_data)\n",
        "#         model_run_avarage_time[name] += time.time() - start\n",
        "\n",
        "#         if is_deeplearning_model:\n",
        "#             output = output.cpu().numpy()\n",
        "\n",
        "#         output = np.clip(output, 0.0, 1.0)\n",
        "\n",
        "#         evaluator.update(valid_label, output, mask)\n",
        "\n",
        "#         valid_time += 1\n",
        "#     model_run_avarage_time[name] /= valid_time\n",
        "#     evaluator.save_pkl(os.path.join(cfg.BENCHMARK.STAT_PATH, name + '.pkl'))\n",
        "\n",
        "# with open(os.path.join(cfg.BENCHMARK.STAT_PATH, 'model_run_average_time.pkl'), 'wb') as f:\n",
        "#     pickle.dump(model_run_avarage_time, f)\n",
        "\n",
        "# ## took around 7 mins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPltkZ0rkEX6"
      },
      "outputs": [],
      "source": [
        "# !zip -r /content/Data-Science-Project-2-2021-2-Nowcasting/models_save.zip /content/Data-Science-Project-2-2021-2-Nowcasting/models_save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLhjnMyLid_d"
      },
      "outputs": [],
      "source": [
        "# for p in os.listdir(os.path.abspath(cfg.BENCHMARK.STAT_PATH)):\n",
        "#   if p != 'conv2d.pkl': continue\n",
        "#   e = pickle.load(open(os.path.join(cfg.BENCHMARK.STAT_PATH, p), 'rb'))\n",
        "#   _, _, csi, hss, _, mse, mae, balanced_mse, balanced_mae, _ = e.calculate_stat()\n",
        "#   print(p.split('.')[0])\n",
        "#   for i, thresh in enumerate(cfg.EVALUATION.THRESHOLDS):\n",
        "#       print('thresh %.1f csi: average %.4f, last frame %.4f; hss: average %.4f, last frame %.4f;'\n",
        "#             % (thresh, csi[:, i].mean(), csi[-1, i], hss[:, i].mean(), hss[-1, i]))\n",
        "\n",
        "#   print(('mse: average %.2f, last frame %.2f\\n' +\n",
        "#       'mae: average %.2f, last frame %.2f\\n'+\n",
        "#       'bmse: average %.2f, last frame %.2f\\n' +\n",
        "#       'bmae: average %.2f, last frame %.2f\\n') % (mse.mean(), mse[-1], mae.mean(), mae[-1],\n",
        "#             balanced_mse.mean(), balanced_mse[-1], balanced_mae.mean(), balanced_mae[-1]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "experiment_conv2d.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "eb1796cbf25d2108f32d5db083036b25e583e4721264bccb55031d3096240637"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
